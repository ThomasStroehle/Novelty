{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThomasStroehle/Novelty/blob/main/novelty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntXU-9KFPRK1"
      },
      "source": [
        "# Novelty and Outlier Detection in idea competitions\n",
        "Installation and loading of the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "agHXUFfmPKuW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install sentence-transformers\n",
        "!pip install requests_html\n",
        "!pip install gensim\n",
        "!pip install sentence_transformers\n",
        "!pip install sacremoses\n",
        "!pip install simcse\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRCAbGiePbKU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6UZCPHPQPDW"
      },
      "source": [
        "Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "5o1gOh1IQRRY"
      },
      "outputs": [],
      "source": [
        "# dataset of idea contest\n",
        "DATASET_FILE = \"/content/drive/MyDrive/novelty/data.csv\" \n",
        "# announcement text of idea contest\n",
        "PRIORS_FILE = \"/content/drive/MyDrive/novelty/announcement_ideas_contest.csv\" \n",
        "# novelty ratings from prolific experiment\n",
        "PROLIFIC_FILE = \"/content/drive/MyDrive/novelty/novelty_prolific.csv\"\n",
        "# backup data\n",
        "BACKUP_DATA_FILE = \"/content/drive/MyDrive/novelty/data.pickle\"\n",
        "# backup prior hand\n",
        "BACKUP_HAND_FILE = \"/content/drive/MyDrive/novelty/prior_hand.pickle\"\n",
        "# backup prior scraped\n",
        "BACKUP_SCRAPED_FILE = \"/content/drive/MyDrive/novelty/prior_scraped.pickle\"\n",
        "# result file\n",
        "RESULT_FILE = \"/content/drive/MyDrive/novelty/result_pain_solution.xlsx\"\n",
        "\n",
        "# question for additional prior web scrapping \n",
        "QUESTION = \"How could paper towels be improved?\" \n",
        "\n",
        "# Sentence Bert\n",
        "SBERT_MODEL = 'all-mpnet-base-v2'\n",
        "EMBEDDING_MAX_LENGTH = 512\n",
        "\n",
        "# GPT-3\n",
        "ENGINE_GPT3 = 'text-embedding-ada-002'\n",
        "OPENAI_API_KEY = 'YOUR KEY'\n",
        "\n",
        "# SIMCSE\n",
        "SIMCSE_MODEL = 'princeton-nlp/sup-simcse-roberta-large'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Preprocessing\n",
        "Mounting Google Drive"
      ],
      "metadata": {
        "id": "d57fZd2SwHKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_xPUF7lEp-09",
        "outputId": "e1f8581e-5600-4361-c455-84488ff44cf6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(DATASET_FILE, index_col=0)\n",
        "prolific = pd.read_csv(PROLIFIC_FILE, index_col=0)\n",
        "prior_hand = pd.read_csv(PRIORS_FILE, on_bad_lines='warn')\n",
        "\n",
        "# Merging of Prolific Ratings into the data set\n",
        "data = pd.merge(data, prolific, on=\"id\", how=\"left\")\n",
        "\n",
        "data.loc[:, ['pain_point', 'solution']] = \\\n",
        "  data.loc[:, ['pain_point', 'solution']].fillna('')\n",
        "\n",
        "data['text'] = data['pain_point'] + data['solution']\n",
        "data['text'] = data['text'].apply(lambda x: re.sub(r'https?://\\S+', '', x))\n",
        "\n",
        "data = data.set_index(['id'])\n",
        "data.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "k-y8lQaTsSOm",
        "outputId": "c03c80c0-1f2c-41ee-d2fe-fe6e0a056adb"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             pain_point  \\\n",
              "id                                                        \n",
              "6537  Kitchen towels are great as they are indispens...   \n",
              "6538  Kitchen rolls are great and the towels are sup...   \n",
              "6539  Kitchen towels are great and a many households...   \n",
              "\n",
              "                                               solution  novelty_researcher  \\\n",
              "id                                                                            \n",
              "6537  New Light works with 30% fewer fibers thanks t...            2.666667   \n",
              "6538  Smaller sheets on the roll so depending on the...            2.333333   \n",
              "6539  A more sustainable triple length roll in a com...            3.000000   \n",
              "\n",
              "      originality_researcher  novelty_expert  novelty_prolific  \\\n",
              "id                                                               \n",
              "6537                2.666667             NaN          2.875000   \n",
              "6538                1.666667             NaN          2.571429   \n",
              "6539                2.000000             NaN          3.363636   \n",
              "\n",
              "                                                   text  \n",
              "id                                                       \n",
              "6537  Kitchen towels are great as they are indispens...  \n",
              "6538  Kitchen rolls are great and the towels are sup...  \n",
              "6539  Kitchen towels are great and a many households...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86f43944-400f-4e01-afe9-454d143bf687\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pain_point</th>\n",
              "      <th>solution</th>\n",
              "      <th>novelty_researcher</th>\n",
              "      <th>originality_researcher</th>\n",
              "      <th>novelty_expert</th>\n",
              "      <th>novelty_prolific</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6537</th>\n",
              "      <td>Kitchen towels are great as they are indispens...</td>\n",
              "      <td>New Light works with 30% fewer fibers thanks t...</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.875000</td>\n",
              "      <td>Kitchen towels are great as they are indispens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6538</th>\n",
              "      <td>Kitchen rolls are great and the towels are sup...</td>\n",
              "      <td>Smaller sheets on the roll so depending on the...</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>Kitchen rolls are great and the towels are sup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6539</th>\n",
              "      <td>Kitchen towels are great and a many households...</td>\n",
              "      <td>A more sustainable triple length roll in a com...</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.363636</td>\n",
              "      <td>Kitchen towels are great and a many households...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86f43944-400f-4e01-afe9-454d143bf687')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86f43944-400f-4e01-afe9-454d143bf687 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86f43944-400f-4e01-afe9-454d143bf687');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 6537,\n            'f': \"6537\",\n        },\n\"Kitchen towels are great as they are indispensable. However, we want to avoid wasting paper. So, is there a way to reduce the amount.\",\n\"New Light works with 30% fewer fibers thanks to smaller-sized rolls and a share of recycled fibers. \\r\\nYet the quality is still very good so one can cope with the daily tasks.\",\n{\n            'v': 2.6666666666666665,\n            'f': \"2.6666666666666665\",\n        },\n{\n            'v': 2.6666666666666665,\n            'f': \"2.6666666666666665\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': 2.875,\n            'f': \"2.875\",\n        },\n\"Kitchen towels are great as they are indispensable. However, we want to avoid wasting paper. So, is there a way to reduce the amount.New Light works with 30% fewer fibers thanks to smaller-sized rolls and a share of recycled fibers. \\r\\nYet the quality is still very good so one can cope with the daily tasks.\"],\n [{\n            'v': 6538,\n            'f': \"6538\",\n        },\n\"Kitchen rolls are great and the towels are super versatile. However, often we wipe small spills and wouldn't need a full sheet. So it feels like wasting paper which isn't good.\",\n\"Smaller sheets on the roll so depending on the job everybody can use the amount really needed. For small spills, half a sheet might be enough and for others just rip off 2 or more.\",\n{\n            'v': 2.333333333333333,\n            'f': \"2.333333333333333\",\n        },\n{\n            'v': 1.6666666666666667,\n            'f': \"1.6666666666666667\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': 2.57142857142857,\n            'f': \"2.57142857142857\",\n        },\n\"Kitchen rolls are great and the towels are super versatile. However, often we wipe small spills and wouldn't need a full sheet. So it feels like wasting paper which isn't good.Smaller sheets on the roll so depending on the job everybody can use the amount really needed. For small spills, half a sheet might be enough and for others just rip off 2 or more.\"],\n [{\n            'v': 6539,\n            'f': \"6539\",\n        },\n\"Kitchen towels are great and a many households use them quite a lot. Best would be a roll lasting forever to have it more seamless. Consumer look for ultimate convienience\",\n\"A more sustainable triple length roll in a compact format without even a core to dispose. \\r\\n* 3x longer lasting rolls - so less changes\\r\\n* No Core ? less waste\\r\\n* Compact pack which need 35% less plastic and less trucks to transport\",\n{\n            'v': 3.0,\n            'f': \"3.0\",\n        },\n{\n            'v': 2.0,\n            'f': \"2.0\",\n        },\n{\n            'v': NaN,\n            'f': \"NaN\",\n        },\n{\n            'v': 3.36363636363636,\n            'f': \"3.36363636363636\",\n        },\n\"Kitchen towels are great and a many households use them quite a lot. Best would be a roll lasting forever to have it more seamless. Consumer look for ultimate convienienceA more sustainable triple length roll in a compact format without even a core to dispose. \\r\\n* 3x longer lasting rolls - so less changes\\r\\n* No Core ? less waste\\r\\n* Compact pack which need 35% less plastic and less trucks to transport\"]],\n        columns: [[\"number\", \"id\"], [\"string\", \"pain_point\"], [\"string\", \"solution\"], [\"number\", \"novelty_researcher\"], [\"number\", \"originality_researcher\"], [\"number\", \"novelty_expert\"], [\"number\", \"novelty_prolific\"], [\"string\", \"text\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reducing data to only rated ideas"
      ],
      "metadata": {
        "id": "SgL0EBErH4wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[data['novelty_researcher'].notnull() | data['novelty_expert'].notnull() | data['novelty_prolific'].notnull(), ]\n",
        "print('Number of reduced ideas: ' + str(data['text'].notnull().sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RtTpXSus7C9d",
        "outputId": "1628684d-4b5a-40f7-a6ba-8b8f59752a87"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reduced ideas: 229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[[\"novelty_researcher\", \"novelty_expert\", \"novelty_prolific\"]].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "FFXZjB8ua3fn",
        "outputId": "f30ac161-279c-4251-a70a-0b07d5425ae5"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       novelty_researcher  novelty_expert  novelty_prolific\n",
              "count          225.000000       58.000000        203.000000\n",
              "mean             3.502222        3.008621          3.696816\n",
              "std              1.266996        1.141723          0.592195\n",
              "min              1.000000        1.000000          2.111111\n",
              "25%              2.666667        2.000000          3.363636\n",
              "50%              3.333333        3.000000          3.777778\n",
              "75%              4.333333        4.000000          4.133929\n",
              "max              7.000000        5.000000          4.777778"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46cc985d-4173-4edb-bb1f-5eb259d54862\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>novelty_researcher</th>\n",
              "      <th>novelty_expert</th>\n",
              "      <th>novelty_prolific</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>225.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>203.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.502222</td>\n",
              "      <td>3.008621</td>\n",
              "      <td>3.696816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.266996</td>\n",
              "      <td>1.141723</td>\n",
              "      <td>0.592195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.666667</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.333333</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.133929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.777778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46cc985d-4173-4edb-bb1f-5eb259d54862')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46cc985d-4173-4edb-bb1f-5eb259d54862 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46cc985d-4173-4edb-bb1f-5eb259d54862');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/fb998edc550c7947/data_table.js\";\n\n      window.createDataTable({\n        data: [[\"count\",\n{\n            'v': 225.0,\n            'f': \"225.0\",\n        },\n{\n            'v': 58.0,\n            'f': \"58.0\",\n        },\n{\n            'v': 203.0,\n            'f': \"203.0\",\n        }],\n [\"mean\",\n{\n            'v': 3.5022222222222217,\n            'f': \"3.5022222222222217\",\n        },\n{\n            'v': 3.0086206896551726,\n            'f': \"3.0086206896551726\",\n        },\n{\n            'v': 3.6968157595004887,\n            'f': \"3.6968157595004887\",\n        }],\n [\"std\",\n{\n            'v': 1.2669955713331351,\n            'f': \"1.2669955713331351\",\n        },\n{\n            'v': 1.1417226535950271,\n            'f': \"1.1417226535950271\",\n        },\n{\n            'v': 0.5921951996474837,\n            'f': \"0.5921951996474837\",\n        }],\n [\"min\",\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 1.0,\n            'f': \"1.0\",\n        },\n{\n            'v': 2.11111111111111,\n            'f': \"2.11111111111111\",\n        }],\n [\"25%\",\n{\n            'v': 2.6666666666666665,\n            'f': \"2.6666666666666665\",\n        },\n{\n            'v': 2.0,\n            'f': \"2.0\",\n        },\n{\n            'v': 3.36363636363636,\n            'f': \"3.36363636363636\",\n        }],\n [\"50%\",\n{\n            'v': 3.333333333333333,\n            'f': \"3.333333333333333\",\n        },\n{\n            'v': 3.0,\n            'f': \"3.0\",\n        },\n{\n            'v': 3.77777777777778,\n            'f': \"3.77777777777778\",\n        }],\n [\"75%\",\n{\n            'v': 4.333333333333333,\n            'f': \"4.333333333333333\",\n        },\n{\n            'v': 4.0,\n            'f': \"4.0\",\n        },\n{\n            'v': 4.133928571428569,\n            'f': \"4.133928571428569\",\n        }],\n [\"max\",\n{\n            'v': 7.0,\n            'f': \"7.0\",\n        },\n{\n            'v': 5.0,\n            'f': \"5.0\",\n        },\n{\n            'v': 4.77777777777778,\n            'f': \"4.77777777777778\",\n        }]],\n        columns: [[\"string\", \"index\"], [\"number\", \"novelty_researcher\"], [\"number\", \"novelty_expert\"], [\"number\", \"novelty_prolific\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH-o2wMyPrLT"
      },
      "source": [
        "# Web scraping for prior knowldege"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "V9zwA7qUPqBU"
      },
      "outputs": [],
      "source": [
        "from requests_html import HTMLSession\n",
        "from requests import Response\n",
        "import requests\n",
        "import urllib\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "def scrape_html(url: str, debug: bool) -> Response:\n",
        "    session = HTMLSession()\n",
        "    response = session.get(url, timeout=10)\n",
        "    if debug:\n",
        "        print(f\"Scraped {url}\")\n",
        "    return response, url\n",
        "\n",
        "def google_query_url(query: str, competition_date: str, page: int) -> str:\n",
        "    if competition_date:\n",
        "        query = f\"{query} before:{competition_date}\"\n",
        "    else:\n",
        "        query = f\"{query}\"\n",
        "    sanitised_query = urllib.parse.quote_plus(query)\n",
        "    return f\"https://www.google.com/search?q={sanitised_query}&start={page*10}\"\n",
        "\n",
        "def find_query_urls(query: str, competition_date: str, debug: bool, pages: int) -> list:\n",
        "    links = []\n",
        "    for page in range(pages):\n",
        "      query_url = google_query_url(query, competition_date, page)\n",
        "      google_search_html, _ = scrape_html(query_url, debug)\n",
        "      links.extend(list(google_search_html.html.absolute_links))\n",
        "    google_urls = ('https://www.google.',\n",
        "                   'https://google.',\n",
        "                   'https://webcache.googleusercontent.',\n",
        "                   'http://webcache.googleusercontent.',\n",
        "                   'https://policies.google.',\n",
        "                   'https://support.google.',\n",
        "                   'https://maps.google.',\n",
        "                   'https://translate.google.')\n",
        "    for url in links[:]:\n",
        "        if url.startswith(google_urls):\n",
        "            links.remove(url)\n",
        "    return links\n",
        "\n",
        "\n",
        "def scrape_html_paragraph_text(scraped_html) -> list:\n",
        "    paragraphs = scraped_html.html.find('p', first=False)\n",
        "    paragraph_texts = [p.text for p in paragraphs]\n",
        "    paragraph_texts_filtered = list(filter(lambda p: bool(re.match(r\"^[A-z].{10,800}([.?!])$\", p)), paragraph_texts))\n",
        "    return paragraph_texts_filtered\n",
        "\n",
        "\n",
        "def scrape_paragraphs_from_query(query: str, competition_date: str, debug: bool, progress_bar: bool, pages: int) -> list:\n",
        "    links = find_query_urls(query, competition_date, debug, pages)\n",
        "    ex = ThreadPoolExecutor(max_workers=16)\n",
        "    futures = [ex.submit(scrape_html, url, debug) for url in links]\n",
        "    bar = tqdm(total=len(links), smoothing=1, disable = not progress_bar)\n",
        "    all_paragraphs = []\n",
        "    for future in as_completed(futures):\n",
        "      try:\n",
        "        scraped, url = future.result()\n",
        "        paragraphs = scrape_html_paragraph_text(scraped)\n",
        "        all_paragraphs.extend([(p, url) for p in paragraphs])\n",
        "        bar.update()\n",
        "      except requests.exceptions.RequestException as e:\n",
        "        if debug:\n",
        "          print(f\"Request error while scraping: {e}\")\n",
        "        bar.update()\n",
        "        continue\n",
        "      except Exception as e:\n",
        "        if debug:\n",
        "          print(f\"Other error while scraping: {e}\")\n",
        "        bar.update()\n",
        "        continue\n",
        "    bar.close()\n",
        "    return all_paragraphs\n",
        "\n",
        "\n",
        "def web_scrape(query: str, competition_date: str = None, debug: bool = False, progress_bar: bool = True, pages=1) -> list:\n",
        "    if debug:\n",
        "        print(f\"Scraping sites for {query}...\")\n",
        "    paragraphs_url = scrape_paragraphs_from_query(query, competition_date, debug, progress_bar, pages)\n",
        "    if debug:\n",
        "        print(f\"Done scraping, found {len(paragraphs_url)} paragraphs.\")\n",
        "    paragraphs = [p for p, url in paragraphs_url]\n",
        "    urls = [url for p, url in paragraphs_url]\n",
        "    results = {'paragraph': paragraphs, 'url': urls}\n",
        "    return results, query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8ThpIu2-voz"
      },
      "outputs": [],
      "source": [
        "prior_paragraphs, _ = web_scrape(query=QUESTION, pages=5)\n",
        "prior_scraped = pd.DataFrame()\n",
        "prior_scraped['text'] = prior_paragraphs['paragraph']\n",
        "\n",
        "# Prior webscraped knowledge\n",
        "prior_scraped.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcNxm1y-Pn4i"
      },
      "source": [
        "# Embeddings calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT-3 Embeddings"
      ],
      "metadata": {
        "id": "eHD6GjGNr7Lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gpt3_embedding(text):\n",
        "  model_output = openai.Embedding.create(\n",
        "    input=text.to_list(),\n",
        "    engine=ENGINE_GPT3,\n",
        "    convert_to_numpy=True)\n",
        "\n",
        "  embedding = []\n",
        "  for i in range(len(model_output['data'])):\n",
        "    embedding.append(model_output['data'][i]['embedding'])\n",
        "\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "Y2rFKFdpv47a"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "data['embedding_ada002']  = get_gpt3_embedding(data['text'])\n",
        "prior_scraped['embedding_ada002']  = get_gpt3_embedding(prior_scraped['text'])\n",
        "prior_hand['embedding_ada002']  = get_gpt3_embedding(prior_hand['text'])"
      ],
      "metadata": {
        "id": "LhgjHJ3dr6E3"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKifbaeL-npv"
      },
      "source": [
        "## sBERT Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "plRoCvBr-nav"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "\n",
        "# Load sBERT embedding model\n",
        "embedding_model = SentenceTransformer(SBERT_MODEL, device=device)\n",
        "embedding_model.max_seq_length = EMBEDDING_MAX_LENGTH\n",
        "\n",
        "# Abbreviation of the encode function\n",
        "def get_sbert_embedding(data_text):\n",
        "  embedding = embedding_model.encode(\n",
        "    data_text.to_list(), \n",
        "    show_progress_bar=True, \n",
        "    convert_to_numpy=True).tolist()\n",
        "  return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vbWXT6AA0HR"
      },
      "outputs": [],
      "source": [
        "# Embedd all data using sBERT\n",
        "data['embedding_sbert'] = get_sbert_embedding(data['text'])\n",
        "prior_scraped['embedding_sbert'] = get_sbert_embedding(prior_scraped['text'])\n",
        "prior_hand['embedding_sbert'] = get_sbert_embedding(prior_hand['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Doc2Vec Embeddings"
      ],
      "metadata": {
        "id": "mXuOKe-8GqRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "\n",
        "# Create training corpus by using all paragraphs from competition and scraped priors\n",
        "corpus = data['text'].to_list() + \\\n",
        "          prior_scraped['text'].to_list() + \\\n",
        "          prior_hand['text'].to_list()\n",
        "corpus = list(map(lambda x: word_tokenize(x), corpus))\n",
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(corpus)]\n",
        "\n",
        "# Train gensim Doc2Vec model on corpus\n",
        "doc2vec_model = Doc2Vec(documents, vector_size=256, window=5, min_count=2, workers=4, epochs=50)\n",
        "\n",
        "def get_doc2vec_embedding(data_text):\n",
        "  embedding = [doc2vec_model.infer_vector(word_tokenize(paragraph), epochs=40) for \\\n",
        "  paragraph in data_text.tolist()]\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "TwRWf1DAFmSm"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate paragraph embeddings from Doc2Vec model\n",
        "data['embedding_doc2vec'] = get_doc2vec_embedding(data['text'])\n",
        "prior_scraped['embedding_doc2vec'] = get_doc2vec_embedding(prior_scraped['text'])\n",
        "prior_hand['embedding_doc2vec'] = get_doc2vec_embedding(prior_hand['text'])"
      ],
      "metadata": {
        "id": "eM5Lh9J_Vcde"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SIMCSE Embeddings"
      ],
      "metadata": {
        "id": "MK_IsFfDEkpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from simcse import SimCSE\n",
        "simcse_model = SimCSE(SIMCSE_MODEL)\n",
        "\n",
        "def get_simcse_embedding(data_text):\n",
        "  embedding = [simcse_model.encode(paragraph, max_length=EMBEDDING_MAX_LENGTH, return_numpy=True) \n",
        "    for paragraph in data_text.tolist()]\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "opcTF9NMMouu"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['embedding_simcse'] = get_simcse_embedding(data['text'])\n",
        "prior_scraped['embedding_simcse'] = get_simcse_embedding(prior_scraped['text'])\n",
        "prior_hand['embedding_simcse'] = get_simcse_embedding(prior_hand['text'])"
      ],
      "metadata": {
        "id": "NaLevfj3G0vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Embeddings"
      ],
      "metadata": {
        "id": "6QzKYPw7BJa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_pickle(BACKUP_DATA_FILE)\n",
        "prior_scraped.to_pickle(BACKUP_SCRAPED_FILE)\n",
        "prior_hand.to_pickle(BACKUP_HAND_FILE)"
      ],
      "metadata": {
        "id": "x46zZVLtBLrD"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_pickle(BACKUP_DATA_FILE)\n",
        "prior_scraped = pd.read_pickle(BACKUP_SCRAPED_FILE)\n",
        "prior_hand = pd.read_pickle(BACKUP_HAND_FILE)"
      ],
      "metadata": {
        "id": "-MuagvRqCAn2"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computation of Novelty and Outlier Scores"
      ],
      "metadata": {
        "id": "Hrtper222FQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local Outlier Factor"
      ],
      "metadata": {
        "id": "R8nnhkfz2Mba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "def lof(embedding, prior, n_neighbors):\n",
        "  lof_model = LocalOutlierFactor(novelty=True, metric='cosine', n_neighbors=n_neighbors).fit(\n",
        "    prior.to_list())\n",
        "  return (-1)*lof_model.score_samples(embedding.to_list())"
      ],
      "metadata": {
        "id": "vFTSGyn73P31"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Bert Embeddings"
      ],
      "metadata": {
        "id": "q6jLOpqK9jQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraped prior pnowledge (Novelty Detection)\n",
        "data['lof_scraped_sbert'] = lof(data['embedding_sbert'], prior_scraped['embedding_sbert'], 10)\n",
        "# Announcement text of idea contest as prior knowledge (Novelty Detection)\n",
        "data['lof_hand_sbert'] = lof(data['embedding_sbert'], prior_hand['embedding_sbert'], 5)\n",
        "# Outlier Detection\n",
        "data['lof_outlier_sbert'] = lof(data['embedding_sbert'], data['embedding_sbert'], 5)"
      ],
      "metadata": {
        "id": "QhmcCLXbHXBR"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-3 Embeddings"
      ],
      "metadata": {
        "id": "HAx6654T3CHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraped prior pnowledge (Novelty Detection)\n",
        "data['lof_scraped_ada002'] = lof(data['embedding_ada002'], prior_scraped['embedding_ada002'], 10)\n",
        "# Announcement text of idea contest as prior knowledge (Novelty Detection)\n",
        "data['lof_hand_ada002'] = lof(data['embedding_ada002'], prior_hand['embedding_ada002'], 5)\n",
        "# Outlier Detection\n",
        "data['lof_outlier_ada002'] = lof(data['embedding_ada002'], data['embedding_ada002'], 5)"
      ],
      "metadata": {
        "id": "ZUH1uvYSy-vN"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doc2Vec"
      ],
      "metadata": {
        "id": "SyOnG0bS3GA2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "eibAJZFW1AS5"
      },
      "outputs": [],
      "source": [
        "# Scraped prior pnowledge (Novelty Detection)\n",
        "data['lof_scraped_doc2vec'] = lof(data['embedding_doc2vec'], prior_scraped['embedding_doc2vec'], 10)\n",
        "# Announcement text of idea contest as prior knowledge (Novelty Detection)\n",
        "data['lof_hand_doc2vec'] = lof(data['embedding_doc2vec'], prior_hand['embedding_doc2vec'], 5)\n",
        "# Outlier Detection\n",
        "data['lof_outlier_doc2vec'] = lof(data['embedding_doc2vec'], data['embedding_doc2vec'], 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIMCSE"
      ],
      "metadata": {
        "id": "wVqMInWe-Z7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraped prior pnowledge (Novelty Detection)\n",
        "data['lof_scraped_simcse'] = lof(data['embedding_simcse'], prior_scraped['embedding_simcse'], 10)\n",
        "# Announcement text of idea contest as prior knowledge (Novelty Detection)\n",
        "data['lof_hand_simcse'] = lof(data['embedding_simcse'], prior_hand['embedding_simcse'], 5)\n",
        "# Outlier Detection\n",
        "data['lof_outlier_simcse'] = lof(data['embedding_simcse'], data['embedding_simcse'], 5)"
      ],
      "metadata": {
        "id": "ZaBTCg5CPFGe"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## kNN Distance Novelty and Outlier Detection"
      ],
      "metadata": {
        "id": "BjqjBWg_--85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kNN_novelty(data: pd.DataFrame, prior: pd.DataFrame, embedding: str, name: str, k = 5):\n",
        "  dist_mat = util.cos_sim(data[embedding].tolist(), prior[embedding].tolist()).numpy()\n",
        "  kNNs = np.flip(np.sort(dist_mat), axis=1)[:,0:k]\n",
        "  data.loc[:, [f'k{i}_{name}' for i in range(1,k+1)]] = 1-kNNs\n",
        "  k1_idx = np.argmax(dist_mat, axis=1)\n",
        "  k1_contents = [prior.iloc[idx, :]['text'] for idx in k1_idx]\n",
        "  data.loc[:, f'k1_{name}_text'] = k1_contents"
      ],
      "metadata": {
        "id": "OPIhOlb-rZlq"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kNN_outlier(data: pd.DataFrame, embedding: str, name: str, k = 5):\n",
        "  dist_mat = util.cos_sim(data[embedding].tolist(), data[embedding].tolist()).numpy()\n",
        "  kNNs = np.flip(np.sort(dist_mat), axis=1)[:,0:k]\n",
        "  data.loc[:, [f'k{i}_{name}' for i in range(1,k+1)]] = 1-kNNs\n",
        "  k1_idx = np.argmax(dist_mat, axis=1)\n",
        "  k1_contents = [data.iloc[idx, :]['text'] for idx in k1_idx]\n",
        "  data.loc[:, f'k1_{name}_text'] = k1_contents"
      ],
      "metadata": {
        "id": "Y2EjofxQ7LtW"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kNN_novelty(data, prior_scraped, embedding='embedding_sbert', name='scraped_sbert')\n",
        "kNN_novelty(data, prior_hand, embedding='embedding_sbert', name='hand_sbert')\n",
        "kNN_outlier(data, embedding='embedding_sbert', name='outlier_sbert')"
      ],
      "metadata": {
        "id": "XlML8Xvz_36y"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kNN_novelty(data, prior_scraped, embedding='embedding_doc2vec', name='scraped_doc2vec')\n",
        "kNN_novelty(data, prior_hand, embedding='embedding_doc2vec', name='hand_doc2vec')\n",
        "kNN_outlier(data, embedding='embedding_doc2vec', name='outlier_doc2vec')"
      ],
      "metadata": {
        "id": "oF4TMQLu_5Qq"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kNN_novelty(data, prior_scraped, embedding='embedding_simcse', name='scraped_simcse')\n",
        "kNN_novelty(data, prior_hand, embedding='embedding_simcse', name='hand_simcse')\n",
        "kNN_outlier(data, embedding='embedding_simcse', name='outlier_simcse')"
      ],
      "metadata": {
        "id": "o8BfFSgE_68y"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kNN_novelty(data, prior_scraped, embedding='embedding_ada002', name='scraped_ada002')\n",
        "kNN_novelty(data, prior_hand, embedding='embedding_ada002', name='hand_ada002')\n",
        "kNN_outlier(data, embedding='embedding_ada002', name='outlier_ada002')"
      ],
      "metadata": {
        "id": "V-GQ4zrvsBuq"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Novelty and Outlier Scores"
      ],
      "metadata": {
        "id": "MEFR4nmPXcna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_pickle(BACKUP_DATA_FILE)\n",
        "prior_scraped.to_pickle(BACKUP_SCRAPED_FILE)\n",
        "prior_hand.to_pickle(BACKUP_HAND_FILE)\n"
      ],
      "metadata": {
        "id": "hOV0y3MfzmAB"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_pickle(BACKUP_DATA_FILE)\n",
        "prior_scraped = pd.read_pickle(BACKUP_SCRAPED_FILE)\n",
        "prior_hand = pd.read_pickle(BACKUP_HAND_FILE)"
      ],
      "metadata": {
        "id": "swwOT7yTIs1U"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation Analysis"
      ],
      "metadata": {
        "id": "TOzpXvxtAGXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation function, which creates a correlation table (correlation value and pvalue) on specific columns."
      ],
      "metadata": {
        "id": "FBNu-nJqgAi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correlation_analysis(data, columns_string):\n",
        "  correlation = []\n",
        "  p_value = []\n",
        "  column_i = []\n",
        "  column_j = []\n",
        "  for i in columns_string:\n",
        "    for j in columns_string:\n",
        "      r = stats.spearmanr(data[i], data[j], nan_policy = 'omit')\n",
        "      correlation.append(np.round(r.correlation,2))\n",
        "      p_value.append(np.round(r.pvalue,2))\n",
        "      column_i.append(i)\n",
        "      column_j.append(j)\n",
        "\n",
        "  result = pd.DataFrame({\"i\":column_i,\n",
        "                         \"j\":column_j,\n",
        "                         \"correlation\": correlation,\n",
        "                         \"p_value\": p_value})\n",
        "  return result"
      ],
      "metadata": {
        "id": "TSVFmCJoFTsu"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Division of the data set into ideas with a short number of tokens and a long number of tokens."
      ],
      "metadata": {
        "id": "IiJ2-14wgTlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['number_tokens'] = data['text'].apply(nltk.word_tokenize).apply(len)\n",
        "data['short'] = data['number_tokens'].apply(lambda x: True if x <= data['number_tokens'].median() else False)\n",
        "\n",
        "data_short = data[data['short'] == True]\n",
        "data_long = data[data['short'] == False]\n",
        "\n",
        "data.short.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO0Er5oAOCSO",
        "outputId": "1f4999d3-39bc-46b1-a455-86a212b79d7d"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     116\n",
              "False    116\n",
              "Name: short, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of ideas "
      ],
      "metadata": {
        "id": "sZVCP3PcgrRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of ideas: ' + str(data['text'].notnull().sum()))\n",
        "print('Number of ratings from researchers: ' + str(data['novelty_researcher'].notnull().sum()))\n",
        "print('Number of ratings from experts: ' + str(data['novelty_expert'].notnull().sum()))\n",
        "print('Number of ratings from research participants (prolific): ' + str(data['novelty_prolific'].notnull().sum()))\n",
        "#\n",
        "print('Number of short ideas: ' + str(data_short['text'].notnull().sum()))\n",
        "print('Number of short ratings from researchers: ' + str(data_short['novelty_researcher'].notnull().sum()))\n",
        "print('Number of short ratings from experts: ' + str(data_short['novelty_expert'].notnull().sum()))\n",
        "print('Number of short ratings from research participants (prolific): ' + str(data_short['novelty_prolific'].notnull().sum()))\n",
        "#\n",
        "print('Number of long ideas: ' + str(data_long['text'].notnull().sum()))\n",
        "print('Number of long ratings from researchers: ' + str(data_long['novelty_researcher'].notnull().sum()))\n",
        "print('Number of long ratings from experts: ' + str(data_long['novelty_expert'].notnull().sum()))\n",
        "print('Number of long ratings from research participants (prolific): ' + str(data_long['novelty_prolific'].notnull().sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rtec-5cOq9y",
        "outputId": "8f33b0b1-29f6-4a6e-8408-d30af6984b90"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of ideas: 232\n",
            "Number of ratings from researchers: 225\n",
            "Number of ratings from experts: 58\n",
            "Number of ratings from research participants (prolific): 203\n",
            "Number of short ideas: 116\n",
            "Number of short ratings from researchers: 112\n",
            "Number of short ratings from experts: 23\n",
            "Number of short ratings from research participants (prolific): 100\n",
            "Number of long ideas: 116\n",
            "Number of long ratings from researchers: 113\n",
            "Number of long ratings from experts: 35\n",
            "Number of long ratings from research participants (prolific): 103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the correlation tables"
      ],
      "metadata": {
        "id": "rq1aZju4g48U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_string = ['novelty_prolific', 'novelty_researcher', 'novelty_expert']\n",
        "\n",
        "for i in ['k1', 'k3', 'lof']:\n",
        "  for j in ['scraped', 'hand', 'outlier']:\n",
        "    for k in ['sbert', 'doc2vec', 'simcse', 'ada002']:\n",
        "      columns_string.append(i + '_' + j + '_' + k)\n",
        "\n",
        "result_all = correlation_analysis(data, columns_string)\n",
        "correlation_all = result_all.pivot(index=\"i\",columns=\"j\", values=\"correlation\")\n",
        "correlation_all = correlation_all.reset_index(level=0)\n",
        "pvalue_all = result_all.pivot(index=\"i\",columns=\"j\", values=\"p_value\")\n",
        "pvalue_all = pvalue_all.reset_index(level=0)\n",
        "\n",
        "result_short = correlation_analysis(data_short, columns_string)\n",
        "correlation_short = result_short.pivot(index=\"i\",columns=\"j\", values=\"correlation\")\n",
        "correlation_short = correlation_short.reset_index(level=0)\n",
        "pvalue_short = result_short.pivot(index=\"i\",columns=\"j\", values=\"p_value\")\n",
        "pvalue_short = pvalue_short.reset_index(level=0)\n",
        "\n",
        "result_long = correlation_analysis(data_long, columns_string)\n",
        "correlation_long = result_long.pivot(index=\"i\",columns=\"j\", values=\"correlation\")\n",
        "correlation_long = correlation_long.reset_index(level=0)\n",
        "pvalue_long = result_long.pivot(index=\"i\",columns=\"j\", values=\"p_value\")\n",
        "pvalue_long = pvalue_long.reset_index(level=0)"
      ],
      "metadata": {
        "id": "Jj9aIBRjQYx9"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing results to excel"
      ],
      "metadata": {
        "id": "cXmv4-2WTYB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.ExcelWriter(RESULT_FILE) as writer:\n",
        "    result_all.to_excel(writer, sheet_name=\"result_all\", index=False)\n",
        "    correlation_all.to_excel(writer, sheet_name=\"correlation_all\", index=False)\n",
        "    pvalue_all.to_excel(writer, sheet_name=\"pvalue_all\", index=False)\n",
        "    result_short.to_excel(writer, sheet_name=\"result_short\", index=False)\n",
        "    correlation_short.to_excel(writer, sheet_name=\"correlation_short\", index=False)\n",
        "    pvalue_short.to_excel(writer, sheet_name=\"pvalue_short\", index=False)\n",
        "    result_long.to_excel(writer, sheet_name=\"result_long\", index=False)\n",
        "    correlation_long.to_excel(writer, sheet_name=\"correlation_long\", index=False)\n",
        "    pvalue_long.to_excel(writer, sheet_name=\"pvalue_long\", index=False)"
      ],
      "metadata": {
        "id": "9J8-w4GpKmGh"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "k3_hand_sbert untersuchen welche ideen am besten und am schlechtesten...\n",
        "\n",
        "k3_scraped_sbert => beide unsion"
      ],
      "metadata": {
        "id": "DQUBgXxuaJ5i"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ikdsv5ZFc8Yv",
        "BR17OFKSNdxC"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}